---
- name: Decommision the k8s stack
  hosts: localhost
  connection: local
  
  # Include the aws account specific cluster variables
  vars_files:
    - vars/defaults.yaml
    - vars/account_configs/{{ environment_type }}-{{ aws_region }}.yaml
    - vaults/{{ platform }}/vault_{{ environment_type }}.yaml

  tasks:
    - include: tasks/setup_for_kube-aws_ops.yaml

    - name: Decom a cluster
      command: kube-aws destroy --force
      environment:
        AWS_ACCESS_KEY_ID: "{{ aws_access_key }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
 
    - name: Untag the public subnets with the clusterid
      command: aws ec2 delete-tags --resources {{ item }} --tags Key=kubernetes.io/cluster/{{ stack_name }},Value=true --region={{ region }}
      environment:
        AWS_ACCESS_KEY_ID: "{{ aws_access_key }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
      with_items:
        - "{{ public_subnet_zone_a }}"
        - "{{ public_subnet_zone_b }}"
        - "{{ public_subnet_zone_c }}"

    - name: Retrieve the Cluster API server ELB
      script: /bin/bash /ansible/files/sh/get_elb.sh
      environment:
        AWS_REGION: "{{ region }}"
        AWS_ACCESS_KEY_ID: "{{ aws_access_key }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        CLUSTER_NAME: "{{ stack_name }}"
      register: api_server_elb
      tags: k-prov

    - name: Delete the DNS entry for the API Server in Route53
      script: /bin/bash /ansible/files/sh/manage-cname.sh
      environment:
        AWS_REGION: "{{ region }}"
        AWS_ACCESS_KEY_ID: "{{ aws_access_key }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        CNAME_ACTION: "DELETE"
        DNS_ZONE: "{{ dns_zone }}"
        HOSTED_ZONE_ID: "{{ route53_hosted_zone_id }}"
        API_DOMAIN_NAME: "{{ stack_name }}-api"
        LB_FQDN: "{{ api_server_elb.stdout }}"
      register: manage_cname_output
      tags: k-prov

    - name: Output manage-cname.sh log
      debug:
        msg: "{{ manage_cname_output }}"

    - name: Decom an EFS instances (Transformers cache and Factset reader)
      efs:
        state: absent
        name: "{{ item }}"
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_access_key }}"
        region: "{{ region }}"
      with_items:
        - "{{ stack_name }}-transformers-cache"
        - "{{ stack_name }}-factset-reader"
      when: (cluster_environment | lower == "publish")

    - name: Delete persistent volume for kafka
      script: /bin/bash /delete-volumes.sh
      environment:
        AWS_REGION: "{{ region }}"
        AWS_ACCESS_KEY_ID: "{{ aws_access_key }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        VOLUME_NAME: "{{ stack_name }}-kafka"
      when: (cluster_environment | lower == "publish" or cluster_environment | lower == "delivery")

    - name: Delete persistent volume for mongo
      script: /bin/bash /delete-volumes.sh
      environment:
        AWS_REGION: "{{ region }}"
        AWS_ACCESS_KEY_ID: "{{ aws_access_key }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        VOLUME_NAME: "{{ stack_name }}-mongo"
      when: (cluster_environment | lower == "publish" or cluster_environment | lower == "delivery")

    - name: Delete persistent volume for Neo4j
      script: /bin/bash /delete-volumes.sh
      environment:
        AWS_REGION: "{{ region }}"
        AWS_ACCESS_KEY_ID: "{{ aws_access_key }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        VOLUME_NAME: "{{ stack_name }}-neo4j"
      when: (cluster_environment | lower == "delivery")

    - name: Delete persistent volume for Prometheus
      script: /bin/bash /delete-volumes.sh
      environment:
        AWS_REGION: "{{ region }}"
        AWS_ACCESS_KEY_ID: "{{ aws_access_key }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        VOLUME_NAME: "{{ stack_name }}-prometheus"
      when: (platform | lower == "pac" or cluster_environment | lower == "publish" or cluster_environment | lower == "delivery")

    - name: Delete persistent volume for Thanos
      script: /bin/bash /delete-volumes.sh
      environment:
        AWS_REGION: "{{ region }}"
        AWS_ACCESS_KEY_ID: "{{ aws_access_key }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        VOLUME_NAME: "{{ stack_name }}-thanos-store"
      when: (platform | lower == "pac" or cluster_environment | lower == "publish" or cluster_environment | lower == "delivery")

    - name: Delete the S3 bucket for Image Publish and generic RW
      s3_bucket:
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_access_key }}"
        region: "{{ region }}"
        name: "{{ item }}"
        state: absent
      with_items:
        - "{{ stack_name }}-imagepublish"
        - "{{ stack_name }}-genericrw"
      when: (cluster_environment | lower == "delivery")

    - name: Delete prometheus S3 bucket
      cloudformation:
        stack_name: "{{ stack_name }}-prometheus-s3"
        state: absent
        aws_access_key: "{{ aws_access_key }}"
        aws_secret_key: "{{ aws_secret_access_key }}"
        region: "{{ region }}"

